{
  "hash": "18705c820123b66a9e7f1487a0e990d8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Estimating Trophic Position Using the Package {trps}\"\nauthor: \"Benjamin L. Hlina\"\ndate: \"2025-04-04\"\ncategories: [Stable Isotopes, Trophic Dynamics, Food Webs]\nimage: \"logo.png\"\nfeed: \n    categories: \n      - R\n---\n\n\n\n## Our Objectives\n\nThe purpose of this vignette is to learn how to estimate trophic position \nof a species using stable isotope data ($\\delta^{13}C$ and $\\delta^{15}N$) using \nthe package  [{trps}](https://benjaminhlina.github.io/trps/). \nWe can estimate trophic position using several different models but for the purpose \nof this vignette a one source model is the simplest and easiest to implement. \nThe one source model is based on equations from [Post (2002)](https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/0012-9658%282002%29083%5B0703%3AUSITET%5D2.0.CO%3B2).\n\nIf you are wanting to use other trophic position models please walk through this vignette and then\ncheck out other vignettes under the [article section](https://benjaminhlina.github.io/trps/articles) of the webpage. \n\n## Trophic Position Model\n\nThe equation for a one source model consists of the following:\n\n$$\n\\text{Trophic Position} = \\lambda + \\frac{(\\delta^{15}N_c - \\delta^{15}N_b)}{\\Delta N}\n$$\n\nWhere $\\lambda$ is the trophic position of the baseline (e.g., `2`), $\\delta^{15}N_c$ is the $\\delta^{15}N$ of the consumer, $\\delta^{15}N_b$ is the mean $\\delta^{15}N$ of the baseline, and $\\Delta N$ is the trophic enrichment factor (e.g., 3.4).\n\nTo use this model with a Bayesian framework, we need to rearrange this equation to the following:\n\n$$\n\\delta^{15}N_c = \\delta^{15}N_b + \\Delta N \\times (\\text{Trophic Position} - \\lambda) \n$$\n\nThe function `one_source_model()` uses this rearranged equation.\n\n## Vignette structure\n\nFirst we need to organize the data prior to running the model. To do this work we will use [{dplyr}](https://dplyr.tidyverse.org/) and [{tidyr}](https://tidyr.tidyverse.org/) but we could also use [{data.table}](https://rdatatable.gitlab.io/data.table/).\n\nWhen running the model we will use [{trps}](https://benjaminhlina.github.io/trps/) and [{brms}](https://paulbuerkner.com/brms/). \n\nOnce we have run the model we will use [{bayesplot}](https://mc-stan.org/bayesplot/) to assess models and then extract posterior draws using [{tidybayes}](http://mjskay.github.io/tidybayes/). Posterior distributions will be plotted using [{ggplot2}](https://ggplot2.tidyverse.org/) and [{ggdist}](https://mjskay.github.io/ggdist/) with colours provided by [{viridis}](https://sjmgarnier.github.io/viridis/).\n\n## Load packages\n\nFirst we load all the packages needed to carry out the analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n{\n  library(bayesplot)\n  library(brms)\n  library(dplyr)\n  library(ggplot2)\n  library(ggdist)\n  library(grid)\n  library(tidybayes)\n  library(tidyr)\n  library(trps)\n  library(viridis)\n}\n```\n:::\n\n\n\n## Assess data\n\nIn [{trps}](https://benjaminhlina.github.io/trps/) we have several data sets, they include stable isotope data ($\\delta^{13}C$ and $\\delta^{15}N$) for a consumer, lake trout (*Salvelinus namaycush*), a benthic baseline, amphipods, and a pelagic baseline, dreissenids, for an ecoregion in Lake Ontario.\n\n### Consumer data\n\nWe check out each data set with the first being the consumer.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconsumer_iso\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 4\n   common_name ecoregion  d13c  d15n\n   <fct>       <fct>     <dbl> <dbl>\n 1 Lake Trout  Embayment -22.9  15.9\n 2 Lake Trout  Embayment -22.5  16.2\n 3 Lake Trout  Embayment -22.8  17.0\n 4 Lake Trout  Embayment -22.3  16.6\n 5 Lake Trout  Embayment -22.5  16.6\n 6 Lake Trout  Embayment -22.3  16.6\n 7 Lake Trout  Embayment -22.3  16.6\n 8 Lake Trout  Embayment -22.5  16.2\n 9 Lake Trout  Embayment -22.9  16.4\n10 Lake Trout  Embayment -22.3  16.3\n# ℹ 20 more rows\n```\n\n\n:::\n:::\n\n\n\nWe can see that this data set contains the `common_name` of the consumer , the `ecoregion` samples were collected from, and $\\delta^{13}C$ (`d13c`) and $\\delta^{15}N$ (`d15n`).\n\n### Baseline data\n\nNext we check out the benthic baseline data set.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbaseline_1_iso\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 14 × 5\n   common_name ecoregion d13c_b1 d15n_b1    id\n   <fct>       <fct>       <dbl>   <dbl> <int>\n 1 Amphipoda   Embayment   -26.2    8.44     1\n 2 Amphipoda   Embayment   -26.6    8.77     2\n 3 Amphipoda   Embayment   -26.0    8.05     3\n 4 Amphipoda   Embayment   -22.1   13.6      4\n 5 Amphipoda   Embayment   -24.3    6.99     5\n 6 Amphipoda   Embayment   -22.1    7.95     6\n 7 Amphipoda   Embayment   -24.7    7.37     7\n 8 Amphipoda   Embayment   -26.6    6.93     8\n 9 Amphipoda   Embayment   -24.6    6.97     9\n10 Amphipoda   Embayment   -22.1    7.95    10\n11 Amphipoda   Embayment   -24.7    7.37    11\n12 Amphipoda   Embayment   -22.1    7.95    12\n13 Amphipoda   Embayment   -24.7    7.37    13\n14 Amphipoda   Embayment   -26.9   10.2     14\n```\n\n\n:::\n:::\n\n\n\nWe can see that this data set contains the `common_name` of the baseline, the `ecoregion` samples were collected from, and $\\delta^{13}C$ (`d13c_b1`) and $\\delta^{15}N$ (`d15n_b1`).\n\n## Organizing data\n\nNow that we understand the data we need to combine both data sets to estimate trophic position for our consumer.\n\nTo do this we first need to make an `id` column in each data set, which will allow us to join them together. We first `arrange()` the data by `ecoregion` and `common_name`. Next we `group_by()` the same variables, and add `id` for each grouping using `row_number()`. Always `ungroup()` the `data.frame` after using `group_by()`. Lastly, we use `dplyr::select()` to rearrange the order of the columns.\n\n### Consumer data\n\nLet's first add `id` to `consumer_iso` data frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon_os <- consumer_iso %>%\n  arrange(ecoregion, common_name) %>%\n  group_by(ecoregion, common_name) %>%\n  mutate(\n    id = row_number()\n  ) %>%\n  ungroup() %>%\n  dplyr::select(id, common_name:d15n)\n```\n:::\n\n\n\n\nYou will notice that I have renamed this object to `con_os` this is \nbecause we are modifying `con_os`. I have done the same to the baseline and \ncombined objects below. \n\n### Baseline data\n\nNext let's add `id` to `baseline_1_iso` data frame. For joining purposes we are going to drop `common_name` from this data frame.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb1_os <- baseline_1_iso %>%\n  arrange(ecoregion, common_name) %>%\n  group_by(ecoregion, common_name) %>%\n  mutate(\n    id = row_number()\n  ) %>%\n  ungroup() %>%\n  dplyr::select(id, ecoregion:d15n_b1)\n```\n:::\n\n\n\n### Joining isotope data\n\nNow that we have the consumer and baseline data sets in a consistent format we can join them by `\"id\"` and `\"ecoregion\"` using `left_join()` from [{dplyr}](https://dplyr.tidyverse.org/).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_iso_os <- con_os %>%\n  left_join(b1_os, by = c(\"id\", \"ecoregion\"))\n```\n:::\n\n\n\nWe can see that we have successfully combined our consumer and baseline data. We need to do one last thing prior to analyzing the data, and that is calculate the mean $\\delta^{13}C$ (`c1`) and $\\delta^{15}N$ (`n1`) for the baseline and add in the constant $\\lambda$ (`l1`) to our data frame. We do this by using `groub_by()` to group the data by our two groups, then using `mutate()` and `mean()` to calculate the mean values.\n\nImportant note, to run the model successfully, columns need to be named `d15n`, `n1`, and `l1`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_iso_os_1 <- combined_iso_os %>%\n  group_by(ecoregion, common_name) %>%\n  mutate(\n    c1 = mean(d13c_b1, na.rm = TRUE),\n    n1 = mean(d15n_b1, na.rm = TRUE),\n    l1 = 2\n  ) %>%\n  ungroup()\n```\n:::\n\n\n\nLet's view our combined data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_iso_os_1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 30 × 10\n      id common_name ecoregion  d13c  d15n d13c_b1 d15n_b1    c1    n1    l1\n   <int> <fct>       <fct>     <dbl> <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1     1 Lake Trout  Embayment -22.9  15.9   -26.2    8.44 -24.6  8.28     2\n 2     2 Lake Trout  Embayment -22.5  16.2   -26.6    8.77 -24.6  8.28     2\n 3     3 Lake Trout  Embayment -22.8  17.0   -26.0    8.05 -24.6  8.28     2\n 4     4 Lake Trout  Embayment -22.3  16.6   -22.1   13.6  -24.6  8.28     2\n 5     5 Lake Trout  Embayment -22.5  16.6   -24.3    6.99 -24.6  8.28     2\n 6     6 Lake Trout  Embayment -22.3  16.6   -22.1    7.95 -24.6  8.28     2\n 7     7 Lake Trout  Embayment -22.3  16.6   -24.7    7.37 -24.6  8.28     2\n 8     8 Lake Trout  Embayment -22.5  16.2   -26.6    6.93 -24.6  8.28     2\n 9     9 Lake Trout  Embayment -22.9  16.4   -24.6    6.97 -24.6  8.28     2\n10    10 Lake Trout  Embayment -22.3  16.3   -22.1    7.95 -24.6  8.28     2\n# ℹ 20 more rows\n```\n\n\n:::\n:::\n\n\n\nIt is now ready to be analyzed!\n\n## Bayesian Analysis\n\nWe can now estimate trophic position for lake trout in an ecoregion of Lake Ontario.\n\nThere are a few things to know about running a Bayesian analysis, I suggest reading these resources:\n\n1.  [Basics of Bayesian Statistics - Book](https://statswithr.github.io/book/)\n2.  [General Introduction to brms](https://www.jstatsoft.org/article/view/v080i01)\n3.  [Estimating non-linear models with brms](https://paulbuerkner.com/brms/articles/brms_nonlinear.html)\n4.  [Nonlinear modelling using nls nlme and brms](https://www.granvillematheson.com/post/nonlinear-modelling-using-nls-nlme-and-brms/)\n5.  [Andrew Proctor's - Module 6](https://andrewproctor.github.io/rcourse/module6.html)\n6.  [van de Schoot et al., (2021)](https://www.nature.com/articles/s43586-020-00001-2)\n\n### Priors\n\nBayesian analyses rely on supplying uninformed or informed prior distributions for each parameter (coefficient; predictor) in the model. The default informed priors for a one source model are the following, $\\Delta N$ assumes a normal distribution (`dn`; $\\mu = 3.4$; $\\sigma = 0.25$), trophic position assumes a uniform distribution (lower bound = 2 and upper bound = 10), $\\sigma$ assumes a uniform distribution (lower bound = 0 and upper bound = 10), and if informed priors are desired for $\\delta^{15}N_b$ (`n1`; $\\mu = 9$; $\\sigma = 1$), we can set the argument `bp` to `TRUE` in all `one_source_` functions.\n\nYou can change these default priors using `one_source_priors_params()`, however, I would suggest becoming familiar with Bayesian analyses, your study species, and system prior to adjusting these values.\n\n### Model convergence\n\nIt is important to always run the model with at least 2 chains. If the model does not converge you can try to increase the following:\n\n1.  The amount of samples that are burned-in (discarded; in `brm()` this can be controlled by the argument `warmup`)\n\n2.  The number of iterative samples retained (in `brm()` this can be controlled by the argument `iter`).\n\n3.  The number of samples drawn (in `brm()` this is controlled by the argument `thin`).\n\n4.  The `adapt_delta` value using `control = list(adapt_delta = 0.95)`.\n\nWhen assessing the model we want $\\hat R$ to be 1 or within 0.05 of 1, which indicates that the variance among and within chains are equal (see [{rstan} documentation on $\\hat R$](https://mc-stan.org/rstan/reference/Rhat.html)), a high value for effective sample size (ESS), trace plots to look \"grassy\" or \"caterpillar like,\" and posterior distributions to look relatively normal.\n\n## Estimating trophic position\n\nWe will use functions from [{trps}](https://benjaminhlina.github.io/trps/) that drop into a [{brms}](https://paulbuerkner.com/brms/) model. These functions are `one_source_model()` which provides `brm()` the formula structure needed to run a one source model. Next `brm()` needs the structure of the priors which is supplied to the `prior` argument using `one_source_priors()`. Lastly, values for these priors are supplied through the `stanvars` argument using `one_source_priors_params()`. You can adjust the mean ($\\mu$), variance ($\\sigma$), or upper and lower bounds (`lb` and `ub`) for each prior of the model using `one_source_priors_params()`, however, only adjust priors if you have a good grasp of Bayesian frameworks and your study system and species.\n\n### Model\n\nLet's run the model!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output_os <- brm(\n  formula = one_source_model(),\n  prior = one_source_priors(),\n  stanvars = one_source_priors_params(),\n  data = combined_iso_os_1,\n  family = gaussian(),\n  chains = 2,\n  iter = 4000,\n  warmup = 1000,\n  cores = 4,\n  seed = 4,\n  control = list(adapt_delta = 0.95)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nCompiling Stan program...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nStart sampling\n```\n\n\n:::\n:::\n\n\n\n### Model output\n\nLet's view the summary of the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output_os\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: d15n ~ n1 + dn * (tp - l1) \n         dn ~ 1\n         tp ~ 1\n   Data: combined_iso_os_1 (Number of observations: 30) \n  Draws: 2 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndn_Intercept     3.38      0.25     2.90     3.87 1.00     1435     1836\ntp_Intercept     4.54      0.19     4.20     4.95 1.00     1430     1885\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.61      0.08     0.48     0.80 1.00     2097     1929\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nWe can see that $\\hat R$ is 1 meaning that variance among and within chains are equal (see [{rstan} documentation on $\\hat R$](https://mc-stan.org/rstan/reference/Rhat.html)) and that ESS is quite large. Overall, this means the model is converging and fitting accordingly.\n\n### Trace plots\n\nLet's view trace plots and posterior distributions for the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model_output_os)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nWe can see that the trace plots look \"grassy\" meaning the model is converging!\n\n## Predictive posterior check \n\nWe can check how well the model is predicting the $\\delta^{15}N$ of the consumer\nusing `pp_check()` from `{bayesplot}`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npp_check(model_output_os)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nUsing 10 posterior draws for ppc type 'dens_overlay' by default.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nWe can see that posteriors draws ($y_{rep}$; light lines) are effectively \nmodeling $\\delta^{15}N$ of the consumer ($y$; dark line). \n\n## Posterior draws\n\nLet's again look at the summary output from the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_output_os\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: d15n ~ n1 + dn * (tp - l1) \n         dn ~ 1\n         tp ~ 1\n   Data: combined_iso_os_1 (Number of observations: 30) \n  Draws: 2 chains, each with iter = 4000; warmup = 1000; thin = 1;\n         total post-warmup draws = 6000\n\nRegression Coefficients:\n             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\ndn_Intercept     3.38      0.25     2.90     3.87 1.00     1435     1836\ntp_Intercept     4.54      0.19     4.20     4.95 1.00     1430     1885\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.61      0.08     0.48     0.80 1.00     2097     1929\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\nWe can see that $\\Delta N$ is estimated to be `3.37` with `l-95% CI` of `2.89`, \nand `u-95% CI` of `3.86`. If we move down to trophic position (`tp`) \nwe see trophic position is estimated to be `4.54` \nwith `l-95% CI` of `4.21`, and `u-95% CI` of `4.96`.\n\n### Extract posterior draws\n\nWe use functions from [{tidybayes}](http://mjskay.github.io/tidybayes/) \nto do this work. First we look at the the names of the variables we want to extract using `get_variables()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_variables(model_output_os)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"b_dn_Intercept\" \"b_tp_Intercept\" \"sigma\"          \"lprior\"        \n [5] \"lp__\"           \"accept_stat__\"  \"stepsize__\"     \"treedepth__\"   \n [9] \"n_leapfrog__\"   \"divergent__\"    \"energy__\"      \n```\n\n\n:::\n:::\n\n\n\nYou will notice that `\"b_tp_Intercept\"` is the name of the variable that we are wanting to extract. We extract posterior draws using `gather_draws()`, and rename `\"b_tp_Intercept\"` to `tp`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost_draws <- model_output_os %>%\n  gather_draws(b_tp_Intercept) %>%\n  mutate(\n    ecoregion = \"Embayment\",\n    common_name = \"Lake Trout\",\n    .variable = \"tp\"\n  ) %>%\n  dplyr::select(common_name, ecoregion, .chain:.value)\n```\n:::\n\n\n\nLet's view the `post_draws`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost_draws\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6,000 × 7\n# Groups:   .variable [1]\n   common_name ecoregion .chain .iteration .draw .variable .value\n   <chr>       <chr>      <int>      <int> <int> <chr>      <dbl>\n 1 Lake Trout  Embayment      1          1     1 tp          4.23\n 2 Lake Trout  Embayment      1          2     2 tp          4.26\n 3 Lake Trout  Embayment      1          3     3 tp          4.39\n 4 Lake Trout  Embayment      1          4     4 tp          4.44\n 5 Lake Trout  Embayment      1          5     5 tp          4.33\n 6 Lake Trout  Embayment      1          6     6 tp          4.74\n 7 Lake Trout  Embayment      1          7     7 tp          5.06\n 8 Lake Trout  Embayment      1          8     8 tp          4.40\n 9 Lake Trout  Embayment      1          9     9 tp          4.42\n10 Lake Trout  Embayment      1         10    10 tp          4.30\n# ℹ 5,990 more rows\n```\n\n\n:::\n:::\n\n\n\nWe can see that this consists of seven variables:\n\n1.  `ecoregion`\n2.  `common_name`\n3.  `.chain`\n4.  `.iteration` (number of sample after burn-in)\n5.  `.draw` (number of samples from `iter`)\n6.  `.variable` (this will have different variables depending on what is supplied to `gather_draws()`)\n7.  `.value` (estimated value)\n\n## Extracting credible intervals\n\nConsidering we are likely using this information for a paper or presentation, it is nice to be able to report the median and credible intervals (e.g., equal-tailed intervals; ETI). We can extract and export these values using `spread_draws()` and `median_qi` from [{tidybayes}](http://mjskay.github.io/tidybayes/).\n\nWe rename `b_tp_Intercept` to `tp`, add the grouping columns, round all columns that are numeric to two decimal points using `mutate_if()`, and rearrange the order of the columns using `dplyr::select()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedians_ci <- model_output_os %>%\n  spread_draws(b_tp_Intercept) %>%\n  median_qi() %>%\n  rename(\n    tp = b_tp_Intercept\n  ) %>%\n  mutate(\n    ecoregion = \"Embayment\",\n    common_name = \"Lake Trout\"\n  ) %>%\n  mutate_if(is.numeric, round, digits = 2) %>%\n  dplyr::select(ecoregion, common_name, tp:.interval)\n```\n:::\n\n\n\nLet's view the output.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedians_ci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 8\n  ecoregion common_name    tp .lower .upper .width .point .interval\n  <chr>     <chr>       <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1 Embayment Lake Trout   4.52    4.2   4.95   0.95 median qi       \n```\n\n\n:::\n:::\n\n\n\nI like to use [{openxlsx}](https://ycphs.github.io/openxlsx/index.html) to export these values into a table that I can use for presentations and papers. For the vignette I am not going to demonstrate how to do this but please check out `{openxlsx}`.\n\n## Plotting posterior distributions – single species or group\n\nNow that we have our posterior draws extracted we can plot them. To analyze *a single* species or group, I like using density plots.\n\n### Density plot\n\nFor this example we first plot the density for posterior draws using `geom_density()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = post_draws, aes(x = .value)) +\n  geom_density() +\n  theme_bw(base_size = 15) +\n  theme(\n    panel.grid = element_blank()\n  ) +\n  labs(\n    x = \"P(Trophic Position | X)\",\n    y = \"Density\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n\n### Point interval\n\nNext we plot it as a point interval plot using `stat_pointinterval()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = post_draws, aes(\n  y = .value,\n  x = common_name\n)) +\n  stat_pointinterval() +\n  theme_bw(base_size = 15) +\n  theme(\n    panel.grid = element_blank()\n  ) +\n  labs(\n    x = \"P(Trophic Position | X)\",\n    y = \"Density\"\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\nCongratulations we have estimated the trophic position for Lake Trout!\n\nI'll demonstrate in another vignette (i.e, [one source - multiple groups](https://benjaminhlina.github.io/trps/articles/article/estimate_trophic_position_one_source_multiple_groups.html)) how to run the model with an iterative process to produce estimates of trophic position for more than one group (e.g., comparing trophic position among species or in this case different ecoregions).\n\nNow that you have gone through a one source model, you may be looking \nto model trophic position using a two source model. Please see the following \nvignette on how to setup and run a two source model \n[Estimate trophic position - two source model](https://benjaminhlina.github.io/trps/articles/article/estimate_trophic_position_two_source_model.html). \nThe same iterative processes used in [one source - multiple groups](https://benjaminhlina.github.io/trps/articles/article/estimate_trophic_position_one_source_multiple_groups.html) can be applied to the two source model.\n\nTo view all vignettes, please check out {trps}'s [webpage](https://benjaminhlina.github.io/trps/index.html). \n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}